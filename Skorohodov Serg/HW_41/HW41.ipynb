{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4ee4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "\n",
    "import glob as gb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b61c5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02357423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10 letters , which are : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n"
     ]
    }
   ],
   "source": [
    "all_letters = os.listdir('C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small')\n",
    "\n",
    "print(f'We have {len(all_letters)} letters , which are : {all_letters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bbd9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for letter A we have  1873 available images\n",
      "for letter B we have  1873 available images\n",
      "for letter C we have  1873 available images\n",
      "for letter D we have  1873 available images\n",
      "for letter E we have  1873 available images\n",
      "for letter F we have  1873 available images\n",
      "for letter G we have  1872 available images\n",
      "for letter H we have  1872 available images\n",
      "for letter I we have  1872 available images\n",
      "for letter J we have  1872 available images\n",
      "-----------------------\n",
      "Total Images are 18726 images\n"
     ]
    }
   ],
   "source": [
    "total_images = 0\n",
    "for letter in all_letters : \n",
    "    available_images = gb.glob(pathname= f'C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small/{letter}/*.png')\n",
    "    total_images+=len(available_images)\n",
    "    print(f'for letter {letter} we have  {len(available_images)} available images')\n",
    "print('-----------------------')    \n",
    "print(f'Total Images are {total_images} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b176d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\A\n",
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\D\n",
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\I\n",
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\G\n",
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\H\n",
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\B\n",
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\F\n",
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\C\n",
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\J\n",
      "Loading data from  C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small\\E\n"
     ]
    }
   ],
   "source": [
    "Datadir = 'C:/Users/SergS/Study/DS04/DS04_2/HW41/notMNIST_small'\n",
    "Categories = ['A', 'D', 'I', 'G', 'H', 'B', 'F', 'C', 'J', 'E']\n",
    "\n",
    "img_size = 80\n",
    "training_data = []\n",
    "\n",
    "for Category in Categories:\n",
    "    path = os.path.join(Datadir, Category)\n",
    "    print(\"Loading data from \", path)\n",
    "    class_num = Categories.index(Category)\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(\n",
    "                path, img), cv2.IMREAD_GRAYSCALE)\n",
    "            img_resize = cv2.resize(img_array, (img_size, img_size))\n",
    "            training_data.append([img_resize, class_num])\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95e3ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)\n",
    "\n",
    "X, y = [], []\n",
    "for feature, label in training_data:\n",
    "    X.append(feature)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
    "X = X / 255.0\n",
    "\n",
    "y = to_categorical(y, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13aab41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd9a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data:   (18724, 80, 80, 1)\n",
      "Train:       (15165, 80, 80, 1)\n",
      "Validation:  (1686, 80, 80, 1)\n",
      "Test:        (1873, 80, 80, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"full data:  \",X.shape)\n",
    "print(\"Train:      \",X_train.shape)\n",
    "print(\"Validation: \",X_val.shape)\n",
    "print(\"Test:       \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a27f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c744300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is  (15915, 80, 80, 1)\n",
      "X_test shape is  (2809, 80, 80, 1)\n",
      "y_train shape is  (15915, 10)\n",
      "y_test shape is  (2809, 10)\n"
     ]
    }
   ],
   "source": [
    "X_part, X_cv, y_part, y_cv = train_test_split(X, y, test_size=0.15, random_state=44, shuffle =True)\n",
    "\n",
    "print('X_train shape is ' , X_part.shape)\n",
    "print('X_test shape is ' , X_cv.shape)\n",
    "print('y_train shape is ' , y_part.shape)\n",
    "print('y_test shape is ' , y_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7acc6b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is  (11936, 80, 80, 1)\n",
      "X_test shape is  (3979, 80, 80, 1)\n",
      "y_train shape is  (11936, 10)\n",
      "y_test shape is  (3979, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_part, y_part, test_size=0.25, random_state=44, shuffle =True)\n",
    "\n",
    "print('X_train shape is ' , X_train.shape)\n",
    "print('X_test shape is ' , X_test.shape)\n",
    "print('y_train shape is ' , y_train.shape)\n",
    "print('y_test shape is ' , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12ff737",
   "metadata": {},
   "outputs": [],
   "source": [
    "KerasModel = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters = 32, kernel_size = 4,  activation = tf.nn.relu , padding = 'same'),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=None, padding='valid'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=4,activation = tf.nn.relu , padding='same'),\n",
    "        keras.layers.MaxPool2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=5,activation = tf.nn.relu , padding='same'),\n",
    "        keras.layers.MaxPool2D(),\n",
    "        keras.layers.Flatten(),    \n",
    "        keras.layers.Dropout(0.5),        \n",
    "        keras.layers.Dense(64),    \n",
    "        keras.layers.Dropout(0.3),            \n",
    "        keras.layers.Dense(units= 10,activation = tf.nn.softmax ),                \n",
    "\n",
    "    ])\n",
    "    \n",
    "\n",
    "KerasModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed568f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b35edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "187/187 [==============================] - 2s 9ms/step - loss: 0.1509 - acc: 0.9535 - val_loss: 0.1976 - val_acc: 0.9455\n",
      "Epoch 2/30\n",
      "187/187 [==============================] - 1s 8ms/step - loss: 0.1290 - acc: 0.9583 - val_loss: 0.2217 - val_acc: 0.9438\n",
      "Epoch 3/30\n",
      "187/187 [==============================] - 1s 8ms/step - loss: 0.1281 - acc: 0.9592 - val_loss: 0.1848 - val_acc: 0.9480\n",
      "Epoch 4/30\n",
      "187/187 [==============================] - 1s 8ms/step - loss: 0.1145 - acc: 0.9645 - val_loss: 0.2105 - val_acc: 0.9430\n",
      "Epoch 5/30\n",
      "187/187 [==============================] - 1s 8ms/step - loss: 0.1224 - acc: 0.9607 - val_loss: 0.2078 - val_acc: 0.9430\n",
      "Epoch 6/30\n",
      "187/187 [==============================] - 1s 8ms/step - loss: 0.1133 - acc: 0.9645 - val_loss: 0.2776 - val_acc: 0.9366\n",
      "Epoch 7/30\n",
      "187/187 [==============================] - 1s 8ms/step - loss: 0.1039 - acc: 0.9682 - val_loss: 0.2281 - val_acc: 0.9470\n",
      "Epoch 8/30\n",
      "185/187 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9686Restoring model weights from the end of the best epoch: 3.\n",
      "187/187 [==============================] - 1s 8ms/step - loss: 0.0954 - acc: 0.9684 - val_loss: 0.2217 - val_acc: 0.9480\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ccf0c0df0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "KerasModel.fit(X_train,y_train,validation_data=(X_cv, y_cv),epochs=30,batch_size=64,verbose=1, callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c470bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 80, 80, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 26, 26, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 13, 13, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                147520    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 216,650\n",
      "Trainable params: 216,522\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "KerasModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4892d02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 4ms/step\n",
      "Prediction Shape is (3979, 10)\n"
     ]
    }
   ],
   "source": [
    "y_pred = KerasModel.predict(X_test)\n",
    "\n",
    "print('Prediction Shape is {}'.format(y_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d1d89c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for sample  1502  the predicted value is   B   , while the actual letter is B\n",
      "for sample  929  the predicted value is   A   , while the actual letter is A\n",
      "for sample  1387  the predicted value is   B   , while the actual letter is B\n",
      "for sample  3538  the predicted value is   F   , while the actual letter is F\n",
      "for sample  3528  the predicted value is   B   , while the actual letter is B\n",
      "for sample  784  the predicted value is   B   , while the actual letter is B\n",
      "for sample  185  the predicted value is   E   , while the actual letter is E\n",
      "for sample  3514  the predicted value is   H   , while the actual letter is H\n",
      "for sample  1710  the predicted value is   G   , while the actual letter is G\n",
      "for sample  960  the predicted value is   C   , while the actual letter is C\n"
     ]
    }
   ],
   "source": [
    "Letters ={0:'A', 1:'B' , 2:'C' ,3:'D' ,4:'E' ,5:'F' ,6:'G' ,7:'H' ,8:'I' ,9:'J' }\n",
    "\n",
    "for i in list(np.random.randint(0,len(X_test) ,size= 10)) : \n",
    "    print(f'for sample  {i}  the predicted value is   {Letters[np.argmax(y_pred[i])]}   , while the actual letter is {Letters[np.argmax(y_test[i])]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20e727a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 5ms/step - loss: 0.1721 - acc: 0.9512\n",
      "Test Loss is 0.17210520803928375\n",
      "Test Accuracy is 0.951244056224823\n"
     ]
    }
   ],
   "source": [
    "ModelLoss, ModelAccuracy = KerasModel.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test Loss is {}'.format(ModelLoss))\n",
    "print('Test Accuracy is {}'.format(ModelAccuracy ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918441c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
